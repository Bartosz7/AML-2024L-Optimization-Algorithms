{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning\n",
    "## Project 1 - Optimization Algorithms\n",
    "### Authors: Bartosz Grabek, Izabela Telejko, Grzegorz ZbrzeÅ¼ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn import preprocessing \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  \n",
    "pd.set_option('display.max_columns', 500)\n",
    "from pandas.api.types import is_object_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating VIF (source: https://stats.stackexchange.com/questions/155028/how-to-systematically-remove-collinear-variables-pandas-columns-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    for column in df:\n",
    "        if is_object_dtype(df[column]):\n",
    "            dummies = pd.get_dummies(df[column], prefix=column)\n",
    "            if np.sum(df[column].isna()) == 0:\n",
    "                dummies = dummies.iloc[:, :-1]\n",
    "            df = df = df.drop(column, axis = 1)\n",
    "            df = df.join(dummies)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(X, thresh=5.0):\n",
    "    X = X.assign(const=1)  # faster than add_constant from statsmodels\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped = True\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix) for ix in range(X.iloc[:, variables].shape[1])]\n",
    "        vif = vif[:-1]  # don't let the constant be removed in the loop.\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            del variables[maxloc]\n",
    "            dropped = True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables[:-1]])\n",
    "    return X.iloc[:, variables[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_employee(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df['EducationBachelors'] = 1 * (df['Education'] == 'Bachelors')\n",
    "    df['EducationMasters'] = 1 * (df['Education'] == 'Masters')\n",
    "    df['Gender'] = df['Gender'].map({'Female': 1, 'Male': 0})\n",
    "    df['EverBenched'] = df['EverBenched'].map({'No': 0, 'Yes': 1})\n",
    "    df.drop(['Education', 'City'], axis=1, inplace=True)\n",
    "    X = calculate_vif(df.drop('LeaveOrNot', axis=1)).to_numpy()\n",
    "    y = df['LeaveOrNot'].to_numpy()\n",
    "    return X, y\n",
    "\n",
    "def preprocess_challenger(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df.drop('gameId', axis=1, inplace=True)\n",
    "    for col in ['blue', 'red']:\n",
    "        for lane in ['BOT_LANE', 'MID_LANE', 'TOP_LANE']:\n",
    "            df[f'{col}FirstTowerLane_{lane}'] = df[f'{col}FirstTowerLane'].apply(lambda x: int(lane in x))\n",
    "        for dragon in ['AIR_DRAGON', 'WATER_DRAGON', 'FIRE_DRAGON', 'EARTH_DRAGON']:\n",
    "            df[f'{col}DragnoType_{dragon}'] = df[f'{col}DragnoType'].apply(lambda x: int(lane in x))\n",
    "        df.drop(f'{col}FirstTowerLane', axis=1, inplace=True)\n",
    "        df.drop(f'{col}DragnoType', axis=1, inplace=True)\n",
    "    X = calculate_vif(df.drop('blueWins', axis=1)).to_numpy()\n",
    "    y = df['blueWins'].to_numpy()\n",
    "    return X, y\n",
    "\n",
    "def preprocess_jungle(filename):\n",
    "    df = arff.loadarff(filename)\n",
    "    df = pd.DataFrame(df[0])\n",
    "    str_df = df.select_dtypes([object])\n",
    "    str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "    for col in str_df:\n",
    "        df[col] = str_df[col]\n",
    "    df = df[df['class'] != 'd']\n",
    "    df[['highest_strength', 'closest_to_den', 'fastest_to_den', 'class']] = df.copy()[['highest_strength', 'closest_to_den', 'fastest_to_den', 'class']].applymap(lambda x: int(x == 'w'))\n",
    "    df = pd.concat([df, pd.get_dummies(df[['white_piece0_advanced', 'black_piece0_advanced']], drop_first=True)], axis=1)\n",
    "    df.drop(['white_piece0_advanced', 'black_piece0_advanced'], axis=1, inplace=True)\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    X = calculate_vif(df.drop('class', axis=1)).to_numpy()\n",
    "    y = df['class'].to_numpy()\n",
    "    return X, y\n",
    "\n",
    "def preprocess_water(filename):\n",
    "    water = pd.read_csv(filename)\n",
    "    water[\"ammonia\"] = water[\"ammonia\"].replace(\"#NUM!\", -100)\n",
    "    water[\"ammonia\"] = water[\"ammonia\"].astype(float)\n",
    "    water[\"ammonia\"] = water[\"ammonia\"].replace(-100, water.loc[water[\"ammonia\"] != -100, \"ammonia\"].mean())\n",
    "    \n",
    "    water[\"is_safe\"] = water[\"is_safe\"].replace(\"#NUM!\", -100)\n",
    "    water[\"is_safe\"] = water[\"is_safe\"].astype(int)\n",
    "    if np.mean( water.loc[water[\"is_safe\"] != -100, \"is_safe\"]) > 0.5:\n",
    "        dominant = 1\n",
    "    else:\n",
    "        dominant = 0\n",
    "    water[\"is_safe\"] = water[\"is_safe\"].replace(-100, dominant)\n",
    "    y_water = water.is_safe.to_numpy()\n",
    "    X_water = water.drop(\"is_safe\", axis=1)\n",
    "    X_water = calculate_vif(X_water).to_numpy()\n",
    "    return X_water, y_water\n",
    "\n",
    "def preprocess_booking(filename):\n",
    "    booking = pd.read_csv(filename).drop([\"Booking_ID\", \"date of reservation\"], axis=1)\n",
    "    booking[\"market segment type\"] = 1*(booking[\"market segment type\"] == \"Online\")\n",
    "    booking[\"booking status\"] = 1*(booking[\"booking status\"] == \"Canceled\")\n",
    "    label_encoder = preprocessing.LabelEncoder() \n",
    "    booking[\"room type\"] = label_encoder.fit_transform(booking[\"room type\"]) \n",
    "    booking = one_hot_encode(booking)\n",
    "    y_booking = booking[\"booking status\"].to_numpy()\n",
    "    X_booking = booking.drop(\"booking status\", axis=1)\n",
    "    X_booking = calculate_vif(X_booking).to_numpy()\n",
    "    return X_booking, y_booking\n",
    "\n",
    "def preprocess_churn(filename):\n",
    "    churn = pd.read_csv(filename)\n",
    "    churn[\"FrequentFlyer\"] = 1*(churn[\"FrequentFlyer\"] == \"Yes\")\n",
    "    churn[\"BookedHotelOrNot\"] = 1*(churn[\"BookedHotelOrNot\"] == \"Yes\")\n",
    "    churn[\"AccountSyncedToSocialMedia\"] = 1*(churn[\"AccountSyncedToSocialMedia\"] == \"Yes\")\n",
    "    churn.loc[churn[\"AnnualIncomeClass\"] == \"Low Income\", \"AnnualIncomeClass\"] = 0\n",
    "    churn.loc[churn[\"AnnualIncomeClass\"] == \"Middle Income\", \"AnnualIncomeClass\"] = 1\n",
    "    churn.loc[churn[\"AnnualIncomeClass\"] == \"High Income\", \"AnnualIncomeClass\"] = 2\n",
    "    churn.AnnualIncomeClass = churn.AnnualIncomeClass.astype(int)\n",
    "    y_churn = churn.Target.to_numpy()\n",
    "    X_churn = churn.drop(\"Target\", axis=1)\n",
    "    X_churn = calculate_vif(X_churn).to_numpy()\n",
    "    return X_churn, y_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining variables:\n",
      "Index(['aluminium', 'ammonia', 'arsenic', 'barium', 'cadmium', 'chloramine',\n",
      "       'chromium', 'copper', 'flouride', 'bacteria', 'viruses', 'lead',\n",
      "       'nitrates', 'nitrites', 'mercury', 'perchlorate', 'radium', 'selenium',\n",
      "       'silver', 'uranium'],\n",
      "      dtype='object')\n",
      "Remaining variables:\n",
      "Index(['number of adults', 'number of children', 'number of weekend nights',\n",
      "       'number of week nights', 'car parking space', 'room type', 'lead time',\n",
      "       'market segment type', 'repeated', 'P-C', 'P-not-C', 'average price',\n",
      "       'special requests', 'type of meal_Meal Plan 1',\n",
      "       'type of meal_Meal Plan 2', 'type of meal_Meal Plan 3'],\n",
      "      dtype='object')\n",
      "Remaining variables:\n",
      "Index(['Age', 'FrequentFlyer', 'AnnualIncomeClass', 'ServicesOpted',\n",
      "       'AccountSyncedToSocialMedia', 'BookedHotelOrNot'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_employee, y_employee = preprocess_employee('data/Employee.csv')\n",
    "X_challenger, y_challenger = preprocess_challenger('data/Challenger_LOL.csv')\n",
    "X_jungle, y_jungle = preprocess_jungle('data/jungle_chess.arff')\n",
    "X_water, y_water = preprocess_water(\"data/water_quality.csv\")\n",
    "X_booking, y_booking = preprocess_booking(\"data/booking.csv\")\n",
    "X_churn, y_churn = preprocess_churn(\"data/churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
